<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Masked IRL: LLM-Guided Reward Disambiguation from Demonstrations and Language">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Masked IRL: LLM-Guided Reward Disambiguation from Demonstrations and Language</title>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-W77JBH4NHE"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-W77JBH4NHE');
  </script>

  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-T3WRXWGZ');</script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <!-- Simple utility styles reused across sections -->
  <style>
    .colored-section {
      background-color: #F8F8F8;
      padding: 20px;
    }

    .colored-section2 {
      background-color: #f3ebde;
      padding: 20px;
    }

    .colored-section3 {
      background-color: #f0eeee;
      padding: 20px;
    }

    ol {
      margin-left: 50px; /* Adjust the value to control the tab size */
    }
  </style>

  <style>
    .image-container {
      display: inline-block;
      margin: 10px; /* Add margin for spacing */
    }

    .equal-height {
      height: 250px; /* Set the desired equal height for both images */
    }
  </style>

  <style>
    .two-column-layout {
      display: flex;
      gap: 20px; /* Space between columns */
      align-items: flex-start; /* Aligns the items at the start of the container */
    }

    .left-column {
      flex: 1; /* Takes up equal space with right column */
    }

    .right-column {
      flex: 1; /* Takes up equal space with left column */
    }

    table {
      width: 100%;
      border-collapse: collapse;
    }

    th, td {
      border: 1px solid #ddd;
      padding: 8px;
      text-align: left;
    }

    th {
      background-color: #f2f2f2;
    }

    .greencheck {
      color: green;
      font-weight: bold;
    }

    /* Task Instruction Caption Style */
    .task-instruction-caption {
      background-color: #f2f2f2; /* Light gray background */
      padding: 10px;
      border-radius: 8px; /* Rounded corners */
      text-align: center;
      margin-bottom: 10px; /* Space between caption and image */
      font-weight: bold;
      margin-top: 8px;
    }

    .figure-item img {
      height: 220px;
      width: auto;
      border: 1px solid #ccc;
      border-radius: 8px;
    }

    .centered-container {
      display: flex;
      flex-direction: column;
      align-items: center;
      text-align: center;
    }

    .interpolation-image {
      width: 300px; /* Fixed width as requested */
      display: block;
      margin: 0 auto; /* Center the image horizontally */
    }

    .wide-figure {
      width: 100%;
      max-width: 1400px;   /* Increase max width */
      margin: 0 auto;       /* Center it */
    }

    .middle-figure-80 {
      width: 80%;
      max-width: 1400px;   /* Increase max width */
      margin: 0 auto;       /* Center it */
    }

    .middle-figure-60 {
      width: 60%;
      max-width: 1400px;   /* Increase max width */
      margin: 0 auto;       /* Center it */
    }
  </style>

  <style>
    /* Ensure the video container is positioned relatively to contain the absolute caption */
    .item {
      position: relative;
      width: 100%;
      height: 100%;
    }

    /* Style the captions to appear on top of the video */
    .caption {
      position: absolute;
      bottom: 10px;
      left: 50%;
      transform: translateX(-50%);
      background-color: rgba(0, 0, 0, 0.5); /* Semi-transparent background */
      color: white;
      padding: 5px 10px;
      border-radius: 5px;
      text-align: center;
      font-size: 14px;
      width: 90%; /* Adjust the width if needed */
    }
  </style>

  <style>
    /* Flexbox layout for figure row */
    .figure-row {
        display: flex;
        justify-content: space-around;
        width: 100%;
        margin-bottom: 10px;
    }

    /* Caption styles with gray background and rounded corners */
    .figure-caption {
        background-color: #f2f2f2; /* Light gray background */
        padding: 10px;
        border-radius: 8px;
        text-align: center;
        font-weight: bold;
        margin-top: 8px;
    }

    /* Style for individual figure items */
    .figure-item {
        display: flex;
        flex-direction: column;
        align-items: center;
        text-align: center;
        margin: 10px;
    }

    /* Ensuring all images have the same height */
    .figure-item img {
        height: 200px; /* Set a uniform height for all images */
        width: auto; /* Maintain aspect ratio */
        border: 1px solid #ccc;
        border-radius: 8px;
    }
  </style>

  <!-- <style>
    .code-block {
        background-color: #d4edda; /* Pastel green background */
        border-radius: 8px; /* Rounded corners */
        padding: 15px; /* Padding inside the box */
        font-family: "Courier New", Courier, monospace; /* Code-like font */
        font-size: 14px; /* Font size */
        white-space: pre-wrap; /* Preserve whitespace and line breaks */
        color: #333; /* Text color */
        margin-bottom: 20px; /* Space below the block */
        overflow-x: auto; /* Horizontal scroll for long lines */
    }
  </style> -->

  <style>
    .code-block {
        background-color: #f0f0f0; /* Light gray background */
        border-radius: 12px; /* Rounded corners */
        padding: 10px; /* Padding inside the box */
        font-family: "Courier New", Courier, monospace; /* Code-like font */
        font-size: 14px; /* Font size */
        white-space: pre-wrap; /* Preserve whitespace and line breaks */
        color: #333; /* Text color */
        margin-bottom: 20px; /* Space below the block */
        overflow-x: auto; /* Horizontal scroll for long lines */
        margin: 0 auto; /* Center the box */
    }
  </style>

  <style>
    .dropdown {
      max-width: 600px;
      margin: 20px auto;
      border-radius: 12px;
      border: 1px solid #ccc;
      background-color: #f0f0f0;
      box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
    }

    .dropdown-header {
      padding: 10px 15px;
      cursor: pointer;
      font-weight: bold;
      background-color: #e0e0e0;
      border-radius: 12px 12px 0 0;
      display: flex;
      align-items: center;
    }

    .dropdown-header::before {
        content: '\25BC'; /* Downward triangle */
      margin-right: 10px;
      transition: transform 0.3s ease;
    }

    .dropdown.open .dropdown-header::before {
        transform: rotate(180deg); /* Rotate triangle when open */
    }

    .dropdown-content {
      display: none;
      padding: 15px;
      font-family: "Courier New", Courier, monospace;
      font-size: 14px;
      white-space: pre-wrap;
      color: #333;
    }

    .dropdown.open .dropdown-content {
      display: block;
    }

    /* Small utility for horizontal figure rows */
    .figure-row {
      display: flex;
      justify-content: space-around;
      flex-wrap: wrap;
      width: 100%;
      margin-bottom: 20px;
    }
  </style>

  <script>
    function toggleDropdown() {
      const dropdown = document.getElementById('gpt4o-dropdown');
      dropdown.classList.toggle('open');
    }
  </script>

  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
</head>

<noscript>
  <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T3WRXWGZ"
          height="0" width="0" style="display:none;visibility:hidden"></iframe>
</noscript>

<body onload="updateSingleVideo(); updateQpredVideo();">

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
</nav>

<!-- ===================== HERO ===================== -->
<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">
            Masked IRL: LLM-Guided Reward Disambiguation<br> from Demonstrations and Language
          </h1>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><a target="_blank" href="https://minyoung1005.github.io/">Minyoung Hwang</a><sup>1</sup>,</span>
            <span class="author-block"><a target="_blank" href="">Alexandra Forsey-Smerek</a><sup>1</sup>,</span>
            <span class="author-block"><a target="_blank" href="https://ndennler.github.io/">Nathaniel Dennler</a><sup>1</sup>,</span>
            <span class="author-block"><a target="_blank" href="https://www.mit.edu/~abobu/">Andreea Bobu</a><sup>1</sup></span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>MIT CSAIL</span>
          </div>

          <br>

          <span class="link-block"><a target="_blank" href="" class="external-link
          button is-normal is-rounded is-light"><span class="icon"><i class="fas fa-file"></i></span><span>ArXiv TBD</span></a></span>

          <!-- Code Link. -->
          <span class="link-block"><a target="_blank" href="https://github.com/MIT-CLEAR-Lab/Masked-IRL" class="external-link
          button is-normal is-rounded is-dark"><span class="icon"><i class="fab fa-github"></i></span><span>Code</span></a></span>

          <!-- <span class="link-block"><a target="_blank" href="" class="external-link
          button is-normal is-rounded is-light"><span class="icon"><i class="fab fa-github"></i></span><span>Code/Dataset Coming Soon</span></a></span> -->

          <!-- <span class="link-block"><a target="_blank" href="" class="external-link
            button is-normal is-rounded is-light"><span class="icon"><i class="fab fa-github"></i></span><span>Dataset</span></a></span> -->
<!--          <span class="link-block">-->
<!--          <a target="_blank" href="" class="external-link button is-normal is-rounded is-dark">-->
<!--            <span class="icon">-->
<!--              <i class="fas fa-database" aria-hidden="true"></i>-->
<!--            </span>-->
<!--            <span>Dataset</span>-->
<!--          </a>-->
<!--        </span>-->
          <br><br>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- ===================== TEASER VIDEO ===================== -->
<section class="hero teaser">
  <div class="container is-fullhd">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-vcentered is-centered">
          <br>
          <video id="teaser" autoplay muted loop width="800" height="100%">
            <source src="media/masked_irl_teaser.mp4" type="video/mp4">
          </video>
        </div>
        <h2 class="subtitle has-text-centered">
          <span>
            How can robots learn reward functions that capture true human preferences when
            <font color="#9900FF">demonstrations and instructions are ambiguous?</font>
          </span>
        </h2>
      </div>
    </div>
  </div>
</section>

<!-- ===================== ABSTRACT ===================== -->
<section class="colored-section">
  <div class="container is-max-desktop is-full-fullhd">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <br/>
          <p>
            Robots can adapt to user preferences by learning reward functions from demonstrations, but with limited data, reward models often overfit to spurious correlations and fail to generalize. 
This happens because demonstrations show robots how to do a task but not what matters for that task, causing the model to focus on irrelevant state details.
Natural language can more directly specify what the robot should focus on, and, in principle, disambiguate between many reward functions consistent with the demonstrations. However, existing language-conditioned reward learning methods typically treat instructions as simple conditioning signals, without fully exploiting their potential to resolve ambiguity. Moreover, real instructions are often ambiguous themselves, so naive conditioning is unreliable. Our key insight is that these two input types carry complementary information: demonstrations show <emph>how</emph> to act, while language specifies <emph>what</emph> is important. We propose <strong>Masked Inverse Reinforcement Learning (Masked IRL)</strong>, a framework that uses large language models (LLMs) to combine the strengths of both input types. Masked IRL infers state-relevance masks from language instructions and enforces invariance to irrelevant state components. When instructions are ambiguous, it uses LLM reasoning to clarify them in the context of the demonstrations. In simulation and on a real robot, Masked IRL outperforms prior language-conditioned IRL methods by up to 15% while using up to 4.7 times less data, demonstrating improved sample-efficiency, generalization, and robustness to ambiguous language.
          </p>
        </div>
      </div>
    </div>
    <br>
  </div>
</section>

<!-- ===================== METHOD OVERVIEW ===================== -->
<section class="section">
  <div class="container is-max-widescreen">
    <div class="rows">
      <div class="row is-full-width">
        <h2 class="title is-3">Method: Masked Inverse Reinforcement Learning</h2>

        <!-- Method text (full width) -->
        <div class="content">
          <p>
            Masked IRL is a language-conditioned reward learning framework that reasons jointly
            over language and demonstrations. Given an ambiguous instruction and a user
            demonstration, an LLM first disambiguates the language in the context of a reference
            (shortest-path) trajectory. The clarified instruction is then passed to a second LLM
            that predicts which state dimensions are relevant for that preference, producing a
            binary state relevance mask.
          </p>
          <p>
            Instead of explicitly zeroing out masked dimensions, Masked IRL applies an
            <strong>implicit masking loss</strong>: it perturbs irrelevant state dimensions with random noise
            and penalizes changes in the predicted reward. This drives the reward model to become
            invariant to irrelevant features while remaining sensitive to the parts of the state that
            language indicates matter for the task. The overall objective combines a standard
            Maximum Entropy IRL loss with this masking loss.
          </p>
          <p>
            At test time, the reward model takes a new instruction and state as input and implicitly
            infers which state components are important through its language-conditioned architecture,
            enabling trajectory optimization for novel language-specified preferences.
          </p>
        </div>

        <!-- Full-width system architecture figure -->
        <div class="centered-container">
          <img src="media/system_overview.png"
               class="interpolation-image wide-figure"
               alt="Overview of the Masked IRL pipeline.">
          <div class="figure-caption">
            System overview of Masked IRL: LLM-based language disambiguation, state mask prediction,
            masking loss, and trajectory optimization.
          </div>
        </div>

      </div>
    </div>
  </div>
</section>


<!-- ===================== EXPERIMENTS ===================== -->
<section class="section" id="experiments">
  <div class="container is-max-widescreen">
    <h2 class="title is-3">Experiments</h2>

    <!-- RQ1: Efficiency of the Masking Loss -->
    <h3 class="title is-4">RQ1: Efficiency of the Masking Loss (Simulation)</h3>
    <p>
      We first evaluate Masked IRL in a PyBullet simulation of an object handover task with a Franka
      arm. Ground-truth rewards are linear combinations of five semantic features (distances to the
      table, human, laptop, human face, and mug orientation), and each preference is paired with a
      language instruction that refers to a subset of these features. We compare Masked IRL to a
      language-conditioned IRL baseline (LC-RL) and an explicit masking baseline that zeros out
      state dimensions indicated as irrelevant by the mask.
    </p>

    <div class="columns is-vcentered is-centered">
      <div class="column is-10">
        <img src="media/exp_results_1.svg"
             class="interpolation-image wide-figure"
             alt="Average win rate vs number of demonstrations for each method.">
        <div class="figure-caption">
          Average win rate when comparing trajectories across sparse, medium, and dense rewards.
        </div>
      </div>
    </div>

    <p>
      Masked IRL achieves higher win rates than LC-RL and remains robust under noisy LLM-generated
      masks, whereas explicit masking degrades sharply when the masks are imperfect. The masking
      loss improves sample efficiency: Masked IRL can match or exceed LC-RL performance with up to
      4.7× fewer demonstrations.
    </p>

    <!-- Example videos per method: simulation -->
    <br>
    <h4 class="title is-5">Example Simulated Trajectories per Method</h4>
    <p>
      Below are example optimized trajectories in simulation.
       <!-- for the instruction
      <em>“Stay away from the table surface while staying away from the laptop.”</em> Each video shows
      a top-down and side view of the trajectory preferred by the learned reward. -->
    </p>

    <div class="columns is-vcentered is-centered">
      <div class="column is-10">
        <img src="media/rq1_vis_1.png"
             class="interpolation-image wide-figure"
             alt="Zero-shot performance and regret on real robot.">
        <div class="figure-caption">
        </div>
      </div>
    </div>

    <div class="columns is-vcentered is-centered">
      <div class="column is-10">
        <img src="media/rq1_vis_2.png"
             class="interpolation-image wide-figure"
             alt="Zero-shot performance and regret on real robot.">
        <div class="figure-caption">
        </div>
      </div>
    </div>

    <br>
    <h4 class="title is-5">Example Visualization of Learned Rewards</h4>
    <p>
      Below are the visualization of learned rewards on trajectory sets. Trajectories with higher reward are drawn in darker blue color.
    </p>

    <div class="columns is-vcentered is-centered">
      <div class="column is-10">
        <img src="media/rq1_vis_3.gif"
             class="interpolation-image wide-figure"
             alt="Zero-shot performance and regret on real robot.">
        <div class="figure-caption">
        </div>
      </div>
    </div>

    <div class="columns is-vcentered is-centered">
      <div class="column is-10">
        <img src="media/rq1_vis_4.gif"
             class="interpolation-image wide-figure"
             alt="Zero-shot performance and regret on real robot.">
        <div class="figure-caption">
        </div>
      </div>
    </div>


    <hr>

    <!-- RQ2: Language ambiguity -->
    <h3 class="title is-4">RQ2: Robustness to Ambiguous Language</h3>
    <p>
      To study robustness to underspecified instructions, we generate ambiguous commands (such as
      referent-omitted “Stay away” or expression-omitted “Table”) for sparse preferences that focus
      on a single feature. Masked IRL uses the LLM disambiguation step to propose clarified
      commands in context (e.g., “Stay away from the table” or “Stay close to the human”), and then
      derives state masks from these clarified instructions.
    </p>

    <!-- TODO: replace with the ambiguity bar chart + mask metrics -->
    <div class="columns is-vcentered is-centered">
      <div class="column is-10">
        <img src="media/masked_irl_results_ambiguity.svg"
             class="interpolation-image middle-figure-60"
             alt="Performance with ambiguous vs disambiguated instructions.">
        <div class="figure-caption">
          Disambiguated instructions (DI) improve state-mask quality and downstream reward prediction
          compared to using ambiguous commands directly (AI).
        </div>
      </div>
    </div>

    <!-- <p>
      Using disambiguated instructions improves mask F1 scores and increases average win rate on
      held-out preferences. Masked IRL trained with disambiguated instructions achieves the best
      generalization, substantially outperforming LC-RL trained directly on ambiguous language.
    </p> -->

    <hr>

    <!-- RQ3: Real robot -->
    <h3 class="title is-4">RQ3: Real-World Evaluation on a Franka Arm</h3>
    <!-- <p>
      Finally, we evaluate zero-shot transfer to a real Franka Emika Panda arm performing an object
      handover task with a human. We collect kinesthetic demonstrations for 50 language-labeled
      preferences and fit reward models using the same training procedure as in simulation. At test
      time, we optimize trajectories over a set of candidate motions and execute the trajectory that
      maximizes the learned reward.
    </p> -->
    <div class="columns is-vcentered is-mobile">
    
    <!-- Left column: text -->
    <div class="column is-8">
      <p>
        Finally, we evaluate zero-shot transfer to a real Franka Emika Panda arm performing an object
        handover task with a human. We collect kinesthetic demonstrations for 50 language-labeled
        preferences and fit reward models using the same training procedure as in simulation. At test
        time, we optimize trajectories over a set of candidate motions and execute the trajectory that
        maximizes the learned reward.
      </p>
    </div>

  <!-- Right column: figure -->
  <div class="column is-4 has-text-centered">
    <img src="media/trajectory_optimization.png"
         style="max-width: 100%; height: auto;"
         class="interpolation-image"
         alt="Trajectory optimization diagram.">
    <div class="figure-caption">
      Trajectory optimization selects the motion that maximizes the learned reward.
    </div>
  </div>

</div>


    <!-- TODO: replace with real-robot bar plots figure -->
    <div class="columns is-vcentered is-centered">
      <div class="column is-10">
        <img src="media/masked_irl_results_real_robot.svg"
             class="interpolation-image middle-figure-80"
             alt="Zero-shot performance and regret on real robot.">
        <div class="figure-caption">
          Zero-shot performance on novel real-robot preferences: win rate, reward variance under
          irrelevant perturbations, and regret of optimized trajectories.
        </div>
      </div>
    </div>

    <p>
      Masked IRL obtains higher win rates, lower reward variance when irrelevant state dimensions
      are perturbed, and substantially lower regret of optimized trajectories than LC-RL and explicit
      masking baselines, indicating better alignment with the underlying human preferences.
    </p>

    <!-- Example videos per method: real robot -->
    <br>
    <h4 class="title is-5">Example Real-Robot Executions per Method</h4>
    <p>
      For the test instruction
      <em>“Stay close to the table surface and away from the human’s face.”</em>:
    </p>



    <div class="columns is-multiline">
      <div class="column is-one-third method-card">
        <span class="method-badge">Baseline</span>
        <strong>LC-RL</strong>
        <!-- TODO: replace src with LC-RL real-robot video -->
        <video class="method-video" autoplay muted loop playsinline>
          <source src="media/real_robot_lcrl_video_only.mp4" type="video/mp4">
        </video>
        <div class="method-caption">
          LC-RL often fails to simultaneously satisfy both distance and safety constraints.
        </div>
      </div>

      <div class="column is-one-third method-card">
        <span class="method-badge">Baseline</span>
        <strong>Explicit Mask (LLM Mask)</strong>
        <!-- TODO: replace src with Explicit Mask real-robot video -->
        <video class="method-video" autoplay muted loop playsinline>
          <source src="media/real_robot_explicitmask_video_only.mp4" type="video/mp4">
        </video>
        <div class="method-caption">
          Explicit masking improves behavior but remains sensitive to mask errors.
        </div>
      </div>

      <div class="column is-one-third method-card">
        <span class="method-badge">Ours</span>
        <strong>Masked IRL (LLM Mask)</strong>
        <!-- TODO: replace src with Masked IRL real-robot video (e.g., ICRA video slice) -->
        <video class="method-video" autoplay muted loop playsinline>
          <source src="media/real_robot_maskedirl_video_only.mp4" type="video/mp4">
        </video>
        <div class="method-caption">
          Masked IRL maintains a safe distance from the human’s face while staying close to the
          table and keeping the cup upright.
        </div>
      </div>
    </div>
  </div>
</section>

<!-- ===================== BIBTEX ===================== -->
<section class="section" id="BibTeX">
  <div class="container is-max-widescreen content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{hwang2025maskedirl,
  title   = {Masked IRL: LLM-Guided Reward Disambiguation from Demonstrations and Language},
  author  = {Hwang, Minyoung and Forsey-Smerek, Alexandra and Dennler, Nathaniel and Bobu, Andreea},
  journal = {arXiv preprint},
  year    = {2025},
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column">
        <div class="content has-text-centered">
          <p>
            This website is based on the
            <a href="https://github.com/nerfies/nerfies.github.io">Nerfies website template</a>,
            which is licensed under a
            <a href="https://creativecommons.org/licenses/by-sa/4.0/">
              Creative Commons Attribution-ShareAlike 4.0 International License
            </a>.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
