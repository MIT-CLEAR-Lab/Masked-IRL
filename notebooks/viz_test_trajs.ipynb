{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "import copy\n",
    "import warnings\n",
    "from glob import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import joblib\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import wandb\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from src.utils.parser import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set color palette\n",
    "sns.set_palette(\"Set2\")\n",
    "palette = sns.color_palette(\"Set2\", 10)\n",
    "\n",
    "# Initialize wandb\n",
    "api = wandb.Api()\n",
    "try:\n",
    "    with open(os.path.expanduser(\"~/.wandb_api_key\"), \"r\") as f:\n",
    "        wandb_key = f.read().strip()\n",
    "    wandb.login(key=wandb_key)\n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: wandb API key file not found. Some features may not work.\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration paths\n",
    "test_trajs_pairs_path = \"../config/data_split_config/0603_frankarobot_obj20_sg10_persg5/test_traj_pairs.json\"\n",
    "with open(test_trajs_pairs_path, \"r\") as f:\n",
    "    test_trajs_pairs = json.load(f)\n",
    "\n",
    "image_folder = \"../data/images/0603_frankarobot_obj20_sg10_persg5\"\n",
    "camera_viewpoint = 0  # Image format: traj_0_view_0.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load theta sampling data\n",
    "thetas_sampled_data_path = \"../config/humans/thetas_sampled_data_0809.json\"\n",
    "with open(thetas_sampled_data_path, \"r\") as f:\n",
    "    thetas_sampled_data = json.load(f)\n",
    "\n",
    "print(\"Available keys:\", thetas_sampled_data.keys())\n",
    "test_thetas_30 = thetas_sampled_data[\"test_thetas_30\"]\n",
    "train_thetas = thetas_sampled_data[\"sampled_thetas\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment configuration\n",
    "env_config = \"../config/reward_learning/obj20_sg10_persg5/frankarobot_obj20_sg10_persg5_maskedrl_llm_mask_mweight1_mnoise1_hidden128_256_128.yaml\"\n",
    "with open(env_config, \"r\") as stream:\n",
    "    params = yaml.safe_load(stream)\n",
    "\n",
    "# Set random seed\n",
    "set_seed(12345)\n",
    "\n",
    "# Make environment\n",
    "env = make_env(params[\"env\"])\n",
    "\n",
    "# Load data and split into train and test\n",
    "indices_file = os.path.join(params[\"irl\"][\"data_split_config_path\"], \"split_indices.json\")\n",
    "all_trajs, train_trajs, test_trajs = load_split_data(\n",
    "    params[\"env\"][\"trajset_file\"],\n",
    "    params[\"env\"][\"per_SG\"],\n",
    "    params[\"env\"][\"train_test_split\"],\n",
    "    indices_file=indices_file\n",
    ")\n",
    "print(f\"Total trajectories: {len(all_trajs)}, Train: {len(train_trajs)}, Test: {len(test_trajs)}\")\n",
    "traj_info = params[\"env\"][\"trajset_file\"].split(\"/\")[-1].split(\".\")[0]\n",
    "\n",
    "# Configure human preferences for feature calculation\n",
    "human_params = {\n",
    "    \"features\": [\"table\", \"laptop\", \"proxemics\", \"human\", \"coffee\"],\n",
    "    \"feature_scaling\": \"normalize\",\n",
    "    \"preferencer\": {\n",
    "        \"theta\": [1.0, 1.0, 1.0, 1.0, 1.0],\n",
    "        \"beta\": 20.0,\n",
    "        \"f_method\": \"boltzmann\",\n",
    "        \"s_method\": \"luce\"\n",
    "    },\n",
    "    \"type\": params[\"env\"][\"type\"]\n",
    "}\n",
    "\n",
    "human = make_human(human_params, env, train_trajs)\n",
    "all_features = np.array([human.calc_features(traj) for traj in all_trajs])\n",
    "print(f\"Feature shape: {all_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_theta_key(theta):\n",
    "    \"\"\"\n",
    "    Generate an interpretable key for a given theta vector.\n",
    "    \n",
    "    Args:\n",
    "        theta: A vector with elements in {-1, 0, 1}\n",
    "        \n",
    "    Returns:\n",
    "        String key, e.g., \"-1_0_1_1_0\" for theta [-1, 0, 1, 1, 0]\n",
    "    \"\"\"\n",
    "    return '_'.join(str(x) for x in theta)\n",
    "\n",
    "\n",
    "# Load additional configuration if needed\n",
    "traj_path = \"../data/traj_sets/0603_frankarobot_obj20_sg10_persg5.npy\"\n",
    "traj_set = np.load(traj_path, allow_pickle=True)\n",
    "print(f\"Trajectory set loaded from {traj_path}\")\n",
    "print(f\"Trajectory set shape: {traj_set.shape}\")\n",
    "\n",
    "# Load human configuration\n",
    "human_config = \"../config/humans/frankarobot_multiple_humans.yaml\"\n",
    "with open(human_config, \"r\") as stream:\n",
    "    humans_params_list = yaml.safe_load(stream)\n",
    "\n",
    "# Load demo indices\n",
    "seed = 12345\n",
    "demo_queries = 10\n",
    "demo_indices_file = os.path.join(params[\"irl\"][\"data_split_config_path\"], f\"demo_indices_100_{seed}.json\")\n",
    "with open(demo_indices_file, \"r\") as f:\n",
    "    saved_demo_indices = json.load(f)\n",
    "    for key in saved_demo_indices.keys():\n",
    "        saved_demo_indices[key] = saved_demo_indices[key][:demo_queries]\n",
    "print(f\"Loaded demo indices from {demo_indices_file}\")\n",
    "\n",
    "# Load preprocessed trajectory data\n",
    "preprocessed_traj_data_path = os.path.join(params[\"irl\"][\"data_split_config_path\"], f\"preprocessed_traj_data_{seed}.pkl\")\n",
    "preprocessed_traj_data = joblib.load(preprocessed_traj_data_path)\n",
    "\n",
    "scaling_coeffs_path = os.path.join(params[\"irl\"][\"data_split_config_path\"], f\"scaling_coeffs_{seed}.pkl\")\n",
    "if os.path.exists(scaling_coeffs_path):\n",
    "    scaling_coeffs = joblib.load(scaling_coeffs_path)\n",
    "\n",
    "# Calculate test features\n",
    "test_features = np.array([human.calc_features(traj) for traj in test_trajs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify preprocessed data shapes\n",
    "print(f\"Preprocessed test states shape: {preprocessed_traj_data['test_states'].shape}\")\n",
    "print(f\"Preprocessed test features shape: {preprocessed_traj_data['test_features'].shape}\")\n",
    "print(f\"Features match: {np.allclose(preprocessed_traj_data['test_features'], test_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check trajectory pair indices range\n",
    "test_trajs_pairs_array = np.array(test_trajs_pairs)\n",
    "print(f\"Trajectory pair indices - Min: {test_trajs_pairs_array.min()}, Max: {test_trajs_pairs_array.max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def annotate_rewards(image, model_name, reward_1, reward_2):\n",
    "    \"\"\"\n",
    "    Annotate the image with the model name and rewards.\n",
    "    \n",
    "    Args:\n",
    "        image: Input image (numpy array)\n",
    "        model_name: Name of the model\n",
    "        reward_1: Reward value for first trajectory\n",
    "        reward_2: Reward value for second trajectory\n",
    "        \n",
    "    Returns:\n",
    "        Annotated image\n",
    "    \"\"\"\n",
    "    # Add margin below the image\n",
    "    image = cv2.copyMakeBorder(image, 0, 50, 0, 0, cv2.BORDER_CONSTANT, value=[255, 255, 255])\n",
    "    cv2.putText(image, f\"{model_name} Reward\", (10, image.shape[0] - 20), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
    "    cv2.putText(image, f\"{reward_1:.2f}\", (280, image.shape[0] - 20), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
    "    cv2.putText(image, f\"{reward_2:.2f}\", (image.shape[1] - 140, image.shape[0] - 20), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
    "    return image\n",
    "\n",
    "\n",
    "# Select test theta (choose from 0 to 29)\n",
    "test_theta_idx = 0\n",
    "test_theta = test_thetas_30[test_theta_idx]\n",
    "print(f\"Test theta: {test_theta}\")\n",
    "\n",
    "# Calculate rewards for test trajectories\n",
    "rewards = test_features.dot(test_theta)\n",
    "traj_pairs_rewards = []\n",
    "count_ties = 0\n",
    "\n",
    "# Visualize pairs of test trajectories\n",
    "for traj_pair_idx in range(len(test_trajs_pairs)):\n",
    "    traj_pair = test_trajs_pairs[traj_pair_idx]\n",
    "    traj_1, traj_2 = traj_pair\n",
    "\n",
    "    # Calculate rewards\n",
    "    reward_1 = rewards[traj_1]\n",
    "    reward_2 = rewards[traj_2]\n",
    "    traj_pairs_rewards.append([reward_1, reward_2])\n",
    "    \n",
    "    if reward_1 == reward_2:\n",
    "        count_ties += 1\n",
    "\n",
    "    # Load and resize images\n",
    "    img_1_path = os.path.join(image_folder, f\"traj_{traj_1}_view_{camera_viewpoint}.png\")\n",
    "    img_2_path = os.path.join(image_folder, f\"traj_{traj_2}_view_{camera_viewpoint}.png\")\n",
    "    img_1 = cv2.imread(img_1_path)\n",
    "    img_2 = cv2.imread(img_2_path)\n",
    "    img_1 = cv2.resize(img_1, (224, 224))\n",
    "    img_2 = cv2.resize(img_2, (224, 224))\n",
    "    \n",
    "    # Create concatenated image with margins\n",
    "    left_margin = 200\n",
    "    margin = 50\n",
    "    img_concat = np.ones(\n",
    "        (img_1.shape[0], img_1.shape[1] + img_2.shape[1] + margin + left_margin, 3),\n",
    "        dtype=np.uint8\n",
    "    ) * 255\n",
    "    img_concat[:, left_margin:(img_1.shape[1] + left_margin), :] = img_1\n",
    "    img_concat[:, img_1.shape[1] + margin + left_margin:, :] = img_2\n",
    "    \n",
    "    # Add white margin above\n",
    "    img_concat = cv2.copyMakeBorder(img_concat, 50, 0, 0, 0, cv2.BORDER_CONSTANT, value=[255, 255, 255])\n",
    "    \n",
    "    # Add text annotations\n",
    "    cv2.putText(img_concat, f\"Pair {traj_pair_idx + 1}\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
    "    cv2.putText(img_concat, f\"Traj {traj_1}\", (60 + left_margin, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
    "    cv2.putText(img_concat, f\"Traj {traj_2}\", (img_1.shape[1] + margin + 60 + left_margin, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)\n",
    "    \n",
    "    # Annotate with rewards\n",
    "    img_concat = annotate_rewards(img_concat, \"GT\", reward_1, reward_2)\n",
    "    \n",
    "    # Display image\n",
    "    display(Image.fromarray(cv2.cvtColor(img_concat, cv2.COLOR_BGR2RGB)))\n",
    "\n",
    "print(f\"Number of ties: {count_ties} out of {len(test_trajs_pairs)}\")\n",
    "traj_pairs_rewards = np.array(traj_pairs_rewards)\n",
    "print(traj_pairs_rewards)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample a new test traj set from a large traj set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trajs_path = \"../data/traj_sets/0815_frankarobot_obj100_sg50_persg50_dict.npy\"\n",
    "all_trajs = np.load(all_trajs_path, allow_pickle=True).item()\n",
    "print(\"Number of Object configurations:\", len(all_trajs))\n",
    "print(all_trajs[0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trajs[0][\"object_centers\"], all_trajs[0][\"trajs\"].shape\n",
    "# output is\n",
    "# ({'HUMAN_CENTER': [-0.35557814847495184, -0.696818238823879, 0.9],\n",
    "#   'LAPTOP_CENTER': [-0.663542735335324, -0.144649949824222, 0.635],\n",
    "#   'TABLE_CENTER': [-0.65, 0.0, 0.0]},\n",
    "#  (2500, 21, 121))\n",
    "# 2500 is 50 start goal pairs, 50 trajs per pair\n",
    "# 100 object configurations\n",
    "\n",
    "test_trajs_pairs_indices = []\n",
    "test_trajs_set = []\n",
    "max_diffs = []\n",
    "\n",
    "# for theta_idx in range(len(test_thetas_30)):\n",
    "#     theta = test_thetas_30[theta_idx]\n",
    "for theta_idx in range(len(train_thetas)):\n",
    "    theta = train_thetas[theta_idx]\n",
    "    print(\"Processing theta:\", theta, \"with index\", theta_idx)\n",
    "    theta_key = get_theta_key(theta)\n",
    "    test_trajs_pairs_indices_per_theta = []\n",
    "    for i in tqdm(range(len(all_trajs))):\n",
    "        # for each object configuration,\n",
    "        trajs = all_trajs[i][\"trajs\"]\n",
    "        # reshape this into 50 x 50 x 21 x 121\n",
    "        trajs = trajs.reshape(50, 50, 21, 121)\n",
    "        # find the pair with highest reward difference\n",
    "        max_diff = -np.inf\n",
    "        max_pair = None\n",
    "        for j in range(trajs.shape[0]):\n",
    "            # for each start goal pair, first calculate reward for each trajectory\n",
    "            # then, choose the trajectory pair with highest reward difference\n",
    "            features = np.array([human.calc_features(traj) for traj in trajs[j]])\n",
    "            rewards = features.dot(theta)\n",
    "            \n",
    "            for k in range(trajs.shape[1]):\n",
    "                for l in range(k + 1, trajs.shape[1]):\n",
    "                    diff = abs(rewards[k] - rewards[l])\n",
    "                    if diff > max_diff:\n",
    "                        max_diff = diff\n",
    "                        max_pair = (k, l, j)\n",
    "        if max_pair is not None:\n",
    "            # add the pair to the list\n",
    "            test_trajs_pairs_indices_per_theta.append([len(test_trajs_set), len(test_trajs_set) + 1])\n",
    "            test_trajs_set.append(trajs[max_pair[2]][max_pair[0]])\n",
    "            test_trajs_set.append(trajs[max_pair[2]][max_pair[1]])\n",
    "            # print(f\"Object configuration {i}, theta {theta_key}, pair {max_pair} with max diff {max_diff:.2f} added.\")\n",
    "            max_diffs.append(max_diff)\n",
    "    # break\n",
    "    # add the pairs for this theta to the main list\n",
    "    test_trajs_pairs_indices.append(test_trajs_pairs_indices_per_theta)\n",
    "# save the test trajectory pairs indices\n",
    "test_trajs_pairs_indices_path = \"../config/data_split_config/0815_frankarobot_obj100_sg50_persg50/seen_theta_test_traj_pairs_indices.json\"\n",
    "if not os.path.exists(os.path.dirname(test_trajs_pairs_indices_path)):\n",
    "    os.makedirs(os.path.dirname(test_trajs_pairs_indices_path))\n",
    "json.dump(test_trajs_pairs_indices, open(test_trajs_pairs_indices_path, \"w\"))\n",
    "print(\"Test trajectory pairs indices saved to\", test_trajs_pairs_indices_path)\n",
    "# save the test trajectory set\n",
    "test_trajs_set_path = \"../config/data_split_config/0815_frankarobot_obj100_sg50_persg50/seen_theta_test_trajs_set.npy\"\n",
    "test_trajs_set = np.array(test_trajs_set)\n",
    "np.save(test_trajs_set_path, test_trajs_set)\n",
    "print(\"Test trajectory set saved to\", test_trajs_set_path)\n",
    "                \n",
    "print(\"Number of test trajectory pairs:\", len(test_trajs_pairs_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_trajs_set.shape\n",
    "# reshape into -1, 2, 21, 121 and sample 100 pairs\n",
    "# repeat this 10 times, save as different test sets\n",
    "# set different random seeds for that\n",
    "test_trajs_set = np.array(test_trajs_set)\n",
    "print(\"Test trajectory set shape:\", test_trajs_set.shape)\n",
    "test_trajs_set_as_pairs = test_trajs_set.reshape(-1, 2, 21, 121)\n",
    "print(\"Test trajectory set as pairs shape:\", test_trajs_set_as_pairs.shape)\n",
    "\n",
    "for random_seed in [12345, 54321, 11111, 22222, 33333, 44444, 55555, 66666, 77777, 88888]:\n",
    "    print(\"Sampling test trajectory set with random seed:\", random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "    sampled_indices = np.random.choice(test_trajs_set_as_pairs.shape[0], size=100, replace=False)\n",
    "    sampled_test_trajs_set = test_trajs_set_as_pairs[sampled_indices]\n",
    "    # print(f\"Random seed {random_seed}, sampled indices: {sampled_indices}\")\n",
    "    # print(f\"Sampled test trajectory set shape: {sampled_test_trajs_set.shape}\")\n",
    "    # save the sampled test trajectory set\n",
    "    sampled_test_trajs_set_path = f\"../config/data_split_config/0815_frankarobot_obj100_sg50_persg50/seen_theta_test_trajs_set_100_{random_seed}.npy\"\n",
    "    if not os.path.exists(os.path.dirname(sampled_test_trajs_set_path)):\n",
    "        os.makedirs(os.path.dirname(sampled_test_trajs_set_path))\n",
    "    np.save(sampled_test_trajs_set_path, sampled_test_trajs_set)\n",
    "    print(\"Sampled test trajectory set saved to\", sampled_test_trajs_set_path)\n",
    "    # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(test_trajs_set).shape\n",
    "# np.array(test_trajs_pairs_indices).shape\n",
    "# len(all_trajs)\n",
    "# trajs.shape\n",
    "test_trajs_pairs_indices\n",
    "# test_trajs_pairs_indices_per_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_diffs.max(), \n",
    "# distribution of max_diffs\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.histplot(max_diffs, bins=30, kde=True)\n",
    "plt.title(\"Distribution of Maximum Reward Differences for Each Theta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate rewards for all_trajs, train_trajs, test_trajs\n",
    "all_trajs_list = []\n",
    "for i in range(len(all_trajs)):\n",
    "    trajs = all_trajs[i][\"trajs\"]\n",
    "    # reshape this into 50 x 50 x 21 x 121\n",
    "    all_trajs_list.append(trajs)\n",
    "all_trajs_list = np.concatenate(all_trajs_list, axis=0)\n",
    "all_features = np.array([human.calc_features(traj) for traj in all_trajs_list])\n",
    "train_features = np.array([human.calc_features(traj) for traj in train_trajs])\n",
    "test_features = np.array([human.calc_features(traj) for traj in test_trajs])\n",
    "# calculate rewards for all features\n",
    "# plot the distribution of rewards for all features. one plot per all, train, test. for each plot, use 5 subplots \n",
    "# for each feature\n",
    "# def plot_feature_rewards(features, rewards, feature_names, title):\n",
    "#     \"\"\"\n",
    "#     Plot the distribution of rewards for each feature.\n",
    "#     \"\"\"\n",
    "#     num_features = features.shape[1]\n",
    "#     fig, axes = plt.subplots(1, num_features, figsize=(20, 5))\n",
    "#     for i in range(num_features):\n",
    "#         sns.histplot(rewards[features[:, i] > 0], ax=axes[i], kde=True)\n",
    "#         axes[i].set_title(f\"{feature_names[i]} (mean: {np.mean(rewards[features[:, i] > 0]):.2f})\")\n",
    "#         axes[i].set_xlabel(\"Reward\")\n",
    "#         axes[i].set_ylabel(\"Density\")\n",
    "#     plt.suptitle(title)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# feature_names = human_params[\"features\"]\n",
    "# # plot for all features\n",
    "# plot_feature_rewards(all_features, all_features.dot(test_thetas_30[0]), feature_names, \"All Features Rewards Distribution\")\n",
    "# plot_feature_rewards(train_features, train_features.dot(test_thetas_30[0]), feature_names, \"Train Features Rewards Distribution\")\n",
    "# plot_feature_rewards(test_features, test_features.dot(test_thetas_30[0]), feature_names, \"Test Features Rewards Distribution\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_reward_distribution(features, title):\n",
    "    \"\"\"\n",
    "    Plot the distribution of rewards.\n",
    "    \"\"\"\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(10, 5))\n",
    "    # sns.histplot(rewards, kde=True)\n",
    "    for i in range(features.shape[1]):\n",
    "        # draw histplot on each subplot ax\n",
    "        sns.histplot(features[:, i], ax=axes[i], kde=True)\n",
    "        axes[i].set_title(f\"Feature {i+1} (mean\") #: {np.mean(features[:, i]):.2f})\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Reward\")\n",
    "    plt.ylabel(\"Density\")\n",
    "    plt.show()\n",
    "# plot for all features\n",
    "plot_reward_distribution(all_features, \"All Features Rewards Distribution\")\n",
    "plot_reward_distribution(train_features, \"Train Features Rewards Distribution\")\n",
    "plot_reward_distribution(test_features, \"Test Features Rewards Distribution\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bullet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
